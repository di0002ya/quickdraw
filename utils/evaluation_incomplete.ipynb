{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance on incomplete Stroke Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_data import get_dataset\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your batch preprocessing function and model definition below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(x,max_strock,max_len):\n",
    "    x_new=torch.zeros(torch.Size([len(x),max_strock,3,max_len]))\n",
    "    for i,item in enumerate(x):\n",
    "        for j,strock in enumerate(item):\n",
    "            strock=torch.Tensor(strock)\n",
    "            x_new[i,j,0,:len(strock[0])]=strock[0]\n",
    "            x_new[i,j,1,:len(strock[0])]=strock[1]\n",
    "        x_new[i,0,2,0]=len(item)\n",
    "    return x_new\n",
    "max_strock,max_len=30,200\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=3,      # input height\n",
    "                out_channels=6,    # n_filters\n",
    "                kernel_size=3      # filter size\n",
    "            ),\n",
    "            nn.ReLU(),    # activation\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "             nn.Conv1d(6,12, 3),\n",
    "             nn.ReLU(),  # activation\n",
    "             nn.MaxPool1d(kernel_size=2)\n",
    "         )\n",
    "        self.conv3 = nn.Sequential(\n",
    "             nn.Conv1d(12,32, 20),\n",
    "             nn.ReLU(),  # activation\n",
    "             nn.MaxPool1d(kernel_size=10)\n",
    "         )\n",
    "        self.out = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x=self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "    \n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.middle_size=middle_size=40\n",
    "        self.gru=nn.GRU(input_size=middle_size,hidden_size=5,num_layers=3,bias=True)\n",
    "        self.cnn=CNN(output_size=middle_size)\n",
    "        self.out=nn.Softmax(dim=-1)\n",
    "    def forward(self, x):\n",
    "        x=x.view(-1,3,max_len)\n",
    "        xx = self.cnn(x)\n",
    "        xx=xx.view(-1,max_strock,self.middle_size).transpose(0,1)\n",
    "        output,_ = self.gru(xx)\n",
    "        to_send=torch.Tensor(torch.Size([xx.shape[1],5])).cuda()\n",
    "        for i in range(xx.shape[1]):\n",
    "            to_send[i]=output[int(x[i*max_strock,2,0])-1,i]\n",
    "        output = self.out(to_send)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='checkpoint.pkl'\n",
    "model=torch.load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of Google's model.\n",
    "\n",
    "Please note that Google's model is based on all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google_model_acc= 0.9134695102211624\n"
     ]
    }
   ],
   "source": [
    "_,_,_,test_Recognized,_,_=get_dataset(dataset_name='1102_05b633244')\n",
    "Google_model_acc=len([i for i in test_Recognized if i])/len(test_Recognized)\n",
    "print(\"Google_model_acc=\",Google_model_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating accuracy score.\n",
    "\n",
    "Before use this function, change the batch preprocessing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(model,test_X,test_Y):\n",
    "    cur_len=0\n",
    "    acc=0\n",
    "    batch_size=512\n",
    "    while cur_len<len(test_X):\n",
    "        model.zero_grad()\n",
    "        minibatch_X=test_X[cur_len:cur_len+batch_size]\n",
    "        #Minibatch preprocessing method here\n",
    "        minibatch_X=unpack(minibatch_X,max_strock,max_len).cuda()\n",
    "        #---------------\n",
    "        minibatch_Y=test_Y[cur_len:cur_len+batch_size]\n",
    "        minibatch_Y=torch.LongTensor(minibatch_Y).cuda()\n",
    "        y_predict=model(minibatch_X)\n",
    "        y_predict=torch.argmax(y_predict,dim=1)\n",
    "        cur_len+=batch_size\n",
    "        acc+=(y_predict==minibatch_Y).sum().item()\n",
    "    return acc/cur_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using the dataset, the get_dataset() function needs dataset_path and dataset_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid5/liuchang/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5,0.7657195060483871\n",
      "0.7,0.8348191784274194\n",
      "0.9,0.8773232736895161\n",
      "1,0.9376575100806451\n"
     ]
    }
   ],
   "source": [
    "def incomplete_test(model,r):\n",
    "    _,_,_,test_Recognized,test_X,testY=get_dataset(dataset_name='1102_05b633244',test_r=r)\n",
    "    print(\"{},{}\".format(r,get_acc(model,test_X,testY)))\n",
    "for r in [0.5,0.7,0.9,1]:\n",
    "    incomplete_test(model,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
