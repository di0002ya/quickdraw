{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthors: Ding Shuya\\n\\nDescription: \\n\\nThis notebook will demonstrate CNN baselie performance  \\n\\nDate: \\nWeek 8 \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Authors: Ding Shuya\n",
    "\n",
    "Description: \n",
    "\n",
    "This notebook will demonstrate CNN baselie performance \n",
    "\n",
    "Output: \n",
    "Output keras models saved in out_data_path\n",
    "\n",
    "Date: \n",
    "Week 8 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### README\n",
    "Introduction...\n",
    "### TODO LIST: \n",
    "1. We need to choose a large datasets (Visualization Analysis Requirements)\n",
    "2. We need to modify and confirm data preprocessing procedures scripts easy to import \n",
    "3. For multiclass classification, we need to select at least 10 classes. \n",
    "4. Why fill feature value using time? CNN preprocessing. \n",
    "5. Current version doesn't consider country factors\n",
    "### CNN Preprocessing Input: \n",
    "1. Dataframe that was converted from raw_data json file\n",
    "2. Category: cat, dog, lion, tiger\n",
    "3. Sample: Number of datapoints used\n",
    "### CNN Preprocessing Output:\n",
    "1. Each drawings are represented using 42 by 28 pixel images \n",
    "2. Values are filled by using time info [Need to investigation: Reason Behind]\n",
    "3. Pickle files are saved in ../quick_draw_output/.. \n",
    "### CNN Preprocessing:\n",
    "1. Add on stroke_number, final_time, total_number_of_datapoints, Ymax, time, total_time_drawing, X, Y, \n",
    "2. Keep correct recognized samples \n",
    "3. Keep storke number < =  15\n",
    "4. Keep final_time < = 20000\n",
    "5. Keep Ymax < = 1.5 \n",
    "6. Normalize X & Y\n",
    "7. Final features None*42*28*1\n",
    "### CNN Model Structures (Keras)\n",
    "1. Total Samples 30000*4 \n",
    "2. Split Ratios 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path = '/export/home/di0002ya/quickdraw/cnn_base'\n",
    "data_path = '/export/home/di0002ya/quickdraw/data/sy_data/quick_draw/'\n",
    "out_data_path = '/export/home/di0002ya/quickdraw/data/sy_data/quick_draw_output/'\n",
    "os.chdir(root_path)\n",
    "from feature_engineering_func_ntu import *\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "np.random.seed(32113)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/di0002ya/quickdraw/cnn_base/feature_engineering_func_ntu.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_cf['final_time'] = [df_cf.loc[i,'drawing'][df_cf.stroke_number[i]-1][2][-1] for i in df_cf.index]\n"
     ]
    }
   ],
   "source": [
    "class_lists = ['cat', 'dog', 'lion', 'tiger']\n",
    "sample = 60000\n",
    "for classes in class_lists:\n",
    "    filepath = data_path + classes + '.ndjson'\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "    feature_engineering_CNN(df,out_data_path, classes, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.read_pickle(out_data_path + 'cat.pkl')\n",
    "df_tiger = pd.read_pickle(out_data_path + 'tiger.pkl')\n",
    "df_lion = pd.read_pickle(out_data_path + 'lion.pkl')\n",
    "df_dog = pd.read_pickle(out_data_path + 'dog.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Label and Feature..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we need to do 4-class classifiers. Hence, we need to combine these multiple datasets. We assume that we will extract 30000 samples from each classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_sample = 30000 \n",
    "random_index1 = np.random.choice(list(df_cat.index), extract_sample, replace=False)\n",
    "random_index2 = np.random.choice(list(df_tiger.index), extract_sample, replace=False)\n",
    "random_index3 = np.random.choice(list(df_lion.index), extract_sample, replace=False)\n",
    "random_index4 = np.random.choice(list(df_dog.index), extract_sample, replace=False)\n",
    "df1 = df_cat.loc[list(random_index1)]\n",
    "df2 = df_tiger.loc[list(random_index2)]\n",
    "df3 = df_lion.loc[list(random_index3)]\n",
    "df4 = df_dog.loc[list(random_index4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df1,df2,df3,df4],axis = 0)\n",
    "df_test = df_test.drop(['countrycode','word'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [0]*extract_sample+[1]*extract_sample + [2]*extract_sample + [3]*extract_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.Series(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 1177)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_test\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization X values \n",
    "data_np = np.array(X)\n",
    "data_key = data_np[:,-1]\n",
    "data_X = data_np[:,0:1176]\n",
    "data_X /= 10000 \n",
    "data_X += 1 \n",
    "data_X[data_X == 1.0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Categorical Representation \n",
    "len_category = len(class_lists)\n",
    "label_cat = np_utils.to_categorical(label,len_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data_X.reshape(len(data_X),42,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Datasets and Testing Datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test =train_test_split(data_X,label_cat,test_size = 0.15, \\\n",
    "                                                    random_state=831713, stratify = label_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Keras CNN Models.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare \n",
    "kernelS = 5 #Kernel size\n",
    "poolS = 2 #Pool size\n",
    "dropout_rate = .20 # Dropout rate \n",
    "batch = 500 # Batch size\n",
    "epochs = 10 # Epochs\n",
    "len_category = 4 # number of classes \n",
    "num_filters = 64\n",
    "dense_neuron = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/di0002ya/miniconda3/envs/ADV_MM/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\", input_shape=(42, 28, 1...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/export/home/di0002ya/miniconda3/envs/ADV_MM/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81600 samples, validate on 20400 samples\n",
      "Epoch 1/10\n",
      "81600/81600 [==============================] - 136s 2ms/step - loss: 0.0963 - acc: 0.7274 - val_loss: 0.0679 - val_acc: 0.8159\n",
      "Epoch 2/10\n",
      "81600/81600 [==============================] - 118s 1ms/step - loss: 0.0639 - acc: 0.8267 - val_loss: 0.0602 - val_acc: 0.8362\n",
      "Epoch 3/10\n",
      "81600/81600 [==============================] - 116s 1ms/step - loss: 0.0570 - acc: 0.8471 - val_loss: 0.0563 - val_acc: 0.8460\n",
      "Epoch 4/10\n",
      "81600/81600 [==============================] - 113s 1ms/step - loss: 0.0514 - acc: 0.8624 - val_loss: 0.0592 - val_acc: 0.8382\n",
      "Epoch 5/10\n",
      "81600/81600 [==============================] - 113s 1ms/step - loss: 0.0475 - acc: 0.8748 - val_loss: 0.0547 - val_acc: 0.8496\n",
      "Epoch 6/10\n",
      "81600/81600 [==============================] - 104s 1ms/step - loss: 0.0433 - acc: 0.8868 - val_loss: 0.0537 - val_acc: 0.8525\n",
      "Epoch 7/10\n",
      "81600/81600 [==============================] - 107s 1ms/step - loss: 0.0400 - acc: 0.8969 - val_loss: 0.0543 - val_acc: 0.8517\n",
      "Epoch 8/10\n",
      "81600/81600 [==============================] - 107s 1ms/step - loss: 0.0361 - acc: 0.9087 - val_loss: 0.0532 - val_acc: 0.8544\n",
      "Epoch 9/10\n",
      "81600/81600 [==============================] - 114s 1ms/step - loss: 0.0329 - acc: 0.9181 - val_loss: 0.0541 - val_acc: 0.8551\n",
      "Epoch 10/10\n",
      "81600/81600 [==============================] - 106s 1ms/step - loss: 0.0301 - acc: 0.9256 - val_loss: 0.0546 - val_acc: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f823a9b5b70>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KERAS model (explained above)\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(num_filters,kernelS,kernelS, activation='relu', input_shape=(42,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(poolS,poolS)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(dense_neuron, activation='relu'))\n",
    "model.add(Dropout(.20))\n",
    "model.add(Dense(len_category, activation='softmax'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size = batch, nb_epoch= epochs, \n",
    "          verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model \n",
    "model.save(out_data_path+'cnn_base_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_label = np.argmax(y_predict,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_label = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8554444444444445"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_label, y_predict_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "adv_mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
