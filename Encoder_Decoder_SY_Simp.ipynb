{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder_Decoder Simplified Data\n",
    "\n",
    "Q: 1. Data filter? Recognized? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Author: Ding Shuya \\nDescription: This doc is used for showing encoder-decoder\\n'calender', 'snowman', 'penguin', 'blackberry', 'teddy-bear'\\n'JP', 'CN', 'DE'\\n\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Author: Ding Shuya \n",
    "Description: This doc is used for showing encoder-decoder\n",
    "'calender', 'snowman', 'penguin', 'blackberry', 'teddy-bear'\n",
    "'JP', 'CN', 'DE'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "root_path = '/export/home/di0002ya/quickdraw/cnn_base'\n",
    "data_path = '/export/home/di0002ya/quickdraw/data/sy_data/quick_draw/'\n",
    "out_data_path = '/export/home/di0002ya/quickdraw/data/sy_data/quick_draw_output/'\n",
    "os.chdir(root_path)\n",
    "from feature_engineering_func_ntu import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing Simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(\"/export/home/di0002ya/quickdraw/toy_dataset/train_X\"), \"rb\") as f:\n",
    "    train_X = pickle.load(f)\n",
    "with open(os.path.join(\"/export/home/di0002ya/quickdraw/toy_dataset/train_Y\"), \"rb\") as f:\n",
    "    train_Y = pickle.load(f)\n",
    "with open(os.path.join(\"/export/home/di0002ya/quickdraw/toy_dataset/test_X\"), \"rb\") as f:\n",
    "    test_X = pickle.load(f)\n",
    "with open(os.path.join(\"/export/home/di0002ya/quickdraw/toy_dataset/test_Y\"), \"rb\") as f:\n",
    "    test_Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df\n",
    "train_X_df = pd.DataFrame(train_X)\n",
    "train_Y_df = pd.DataFrame(train_Y)\n",
    "test_X_df = pd.DataFrame(test_X)\n",
    "test_Y_df = pd.DataFrame(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "# Find Max Stroke Per Drawings \n",
    "df = train_X_df \n",
    "Nmax = max(train_X_df.shape[1], test_X_df.shape[1])\n",
    "print(Nmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _array_normalizer(array1,Xmin,Xmax,array_min):\n",
    "    '''\n",
    "    function:\n",
    "        - normalize X,Y array by range of X\n",
    "        - used in feature_eng_pt2\n",
    "    input:\n",
    "        array1 = array that you want to normalize (1D array or list)\n",
    "        Xmin = minimum value of your X array (int)\n",
    "        Xmax = maximum value of your X array (int)\n",
    "        array_min = minimum value of array1\n",
    "\n",
    "    output:\n",
    "        normalized array of array1\n",
    "    '''\n",
    "    return (np.array(array1)-np.array([array_min]*len(array1)))/float(Xmax-Xmin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cnn(df_cf, ls): \n",
    "    df_cf.index = range(len(df_cf))\n",
    "    Ymax_list = []\n",
    "    image_list = []\n",
    "    # Add Stroke Number Info\n",
    "    len_info = []\n",
    "    for element in ls:\n",
    "        len_info.append(len(element))\n",
    "    df_cf['stroke_number'] = pd.DataFrame(len_info)\n",
    "    #ith Drawings\n",
    "    for i in df_cf.index:\n",
    "        num = df_cf.loc[i,'stroke_number']\n",
    "        #jth Stroke\n",
    "        X = []\n",
    "        Y = []\n",
    "        Ymax = []\n",
    "        ttnum_dp = []\n",
    "        Tdifftemp = []\n",
    "        for stroke in range(num):\n",
    "            stroke_list_X = df_cf.loc[i][stroke][0] \n",
    "            stroke_list_Y = df_cf.loc[i][stroke][1] \n",
    "            Xmintemp = np.min(stroke_list_X)-10\n",
    "            Xmaxtemp = np.max(stroke_list_X)+10\n",
    "            Ymintemp = np.min(stroke_list_Y)-10\n",
    "            Xnorm = _array_normalizer(stroke_list_X, Xmintemp,Xmaxtemp,Xmintemp)\n",
    "            Ynorm = _array_normalizer(stroke_list_Y, Xmintemp,Xmaxtemp,Ymintemp)\n",
    "            Ymax.append(np.max(Ynorm))\n",
    "            X.append(Xnorm)\n",
    "            Y.append(Ynorm)\n",
    "            ttnum_dp.append(len(Ynorm))\n",
    "            Tdifftemp.append(1)\n",
    "            image_pile = np.zeros((num,1176))\n",
    "            image = np.zeros((42,28))\n",
    "            xarray = np.around(np.array(X[stroke])*28)\n",
    "            yarray = np.around(np.array(Y[stroke])*42/float(Ymax[stroke]))\n",
    "            xarray[xarray>=28.] = 27\n",
    "            yarray[yarray>=42.] = 41\n",
    "            for item in range(len(xarray)):\n",
    "                image[int(np.around(yarray[item])),int(np.around(xarray[item]))] = Tdifftemp[stroke]\n",
    "            image_pile[stroke] = image.reshape(1,1176)\n",
    "        Ymax_list.append(Ymax)\n",
    "        image_list.append(image_pile)\n",
    "    return Ymax_list, image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Ymax_list, Train_image_list = rnn_cnn(train_X_df, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Ymax_list, Test_image_list = rnn_cnn(test_X_df, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(Nmax, image_list):\n",
    "    pad_width = Nmax \n",
    "    image_full_list = []\n",
    "    for i in range(len(image_list)):\n",
    "        pad_ar = np.zeros((pad_width - image_list[i].shape[0],1176))\n",
    "        image_full_list.append(np.vstack((image_list[i],pad_ar)))\n",
    "    image_full_ar = np.array(image_full_list)\n",
    "    return image_full_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_image_full_ar = pad_list(Nmax,Train_image_list)\n",
    "Test_image_full_ar = pad_list(Nmax,Test_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26758, 60, 1176)\n"
     ]
    }
   ],
   "source": [
    "print(Train_image_full_ar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6690, 60, 1176)\n"
     ]
    }
   ],
   "source": [
    "print(Test_image_full_ar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape input to (seq_len, batch, input_size)\n",
    "train_dset = np.reshape(Train_image_full_ar, (Train_image_full_ar.shape[1],\n",
    "                                              Train_image_full_ar.shape[0],Train_image_full_ar.shape[2]))\n",
    "train_dset = torch.from_numpy(train_dset).float()\n",
    "test_dset = np.reshape(Test_image_full_ar, (Test_image_full_ar.shape[1],Test_image_full_ar.shape[0],\n",
    "                                       Test_image_full_ar.shape[2]))\n",
    "test_dset = torch.from_numpy(test_dset).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 26758, 1176])\n"
     ]
    }
   ],
   "source": [
    "print(train_dset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26758])\n",
      "torch.Size([6690])\n"
     ]
    }
   ],
   "source": [
    "#Reshape Labels \n",
    "train_label = torch.from_numpy(np.array(train_Y))\n",
    "print(train_label.shape)\n",
    "test_label = torch.from_numpy(np.array(test_Y))\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split 0.1 Training Data as Evaluation Datasets \n",
    "val_label = train_label[0:2000]\n",
    "train_rem_label = train_label[2000:]\n",
    "val_dset = train_dset[:,0:2000,:]\n",
    "train_rem_dset = train_dset[:,2000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Tune Parameters \n",
    "args={}\n",
    "args['epoch'] = 2\n",
    "args['hidden_size'] = 4000\n",
    "args['batch_size'] = 512\n",
    "args['lr'] = 5\n",
    "args['output_size'] = 5\n",
    "args['mid_size'] = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_decoder_1(nn.Module):\n",
    "    def __init__(self, hidden_size, init_size, mid_size,output_size):\n",
    "        super(encoder_decoder_1, self).__init__()\n",
    "        self.encLSTM1 = nn.LSTM(init_size, hidden_size)\n",
    "        self.encLSTM2 = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, mid_size)\n",
    "        self.decConv1 = nn.Conv2d(1, 1, kernel_size = 4, padding=0, stride=2)\n",
    "        self.decConv2 = nn.Conv2d(1, 1, kernel_size = 3, padding=1, stride=2)\n",
    "        self.output = nn.Linear(256, output_size)\n",
    "    def forward(self, h_init, c_init, word_seq):\n",
    "        h_seq, (h_final,c_final) = self.encLSTM1(word_seq, (h_init,c_init))\n",
    "        score_final = self.linear(h_final)\n",
    "        score_final = score_final.view(score_final.shape[1],1,64,64)\n",
    "        x = self.decConv1(score_final)\n",
    "        x = self.decConv2(x)\n",
    "        x = x.view(x.shape[0],x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        print(x)\n",
    "        y = self.output(x)\n",
    "        print(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_decoder_1(\n",
      "  (encLSTM1): LSTM(1176, 4000)\n",
      "  (encLSTM2): LSTM(4000, 4000)\n",
      "  (linear): Linear(in_features=4000, out_features=4096, bias=True)\n",
      "  (decConv1): Conv2d(1, 1, kernel_size=(4, 4), stride=(2, 2))\n",
      "  (decConv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (output): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = encoder_decoder_1(args['hidden_size'],1176,args['mid_size'],args['output_size'])\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_dset.mean()\n",
    "std = train_dset.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Versions..\n",
    "# net = net.to(device)\n",
    "# mean = mean.to(device)\n",
    "# std = std.to(device)\n",
    "# print(torch.__version__)\n",
    "# net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define Learning Rate \n",
    "my_lr = args['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set(args, net, val_label, val_dset, device, mean, std):\n",
    "    running_error = 0\n",
    "    num_batches = 0 \n",
    "    for i in range(0,test_label.shape[0]):\n",
    "        minibatch_data = val_dset[:,count:count+bs,:]\n",
    "        minibatch_label = val_label[count:count+bs]\n",
    "        # Send to gpu \n",
    "#         minibatch_data = minibatch_data.to(device)\n",
    "#         minibatch_label = minibatch_label.to(device)\n",
    "        # Normalized minibatch data\n",
    "        inputs = (minibatch_data - mean) /std\n",
    "        # Compute output \n",
    "        h = torch.zeros(1, args['batch_size'], args['hidden_size'])\n",
    "        c = torch.zeros(1, args['batch_size'], args['hidden_size'])\n",
    "        h = h.detach()\n",
    "        c = c.detach()\n",
    "#         # Send to gpu\n",
    "#         h = h.to(device)\n",
    "#         c = c.to(device)\n",
    "        inputs.requires_grad_()\n",
    "        y = net(h, c, inputs)\n",
    "        error = get_error(y.detach(), minibatch_label)\n",
    "        running_error += error.item()\n",
    "        num_batches +=1\n",
    "    total_error = running_error/num_batches\n",
    "    print('error rate on test set =', total_error*100,'percent')\n",
    "    return total_error \n",
    "\n",
    "def train_enc_dec(args, net, my_lr, train_label, train_dset, device, mean, std, output,name, val_label, val_dset):\n",
    "    create_dir(output)\n",
    "    best_error = 1000000\n",
    "    logger = Logger(os.path.join(output,'log.txt'))\n",
    "    for epoch in range(args['epoch']):\n",
    "        print('strat new epoch')\n",
    "        bs = args['batch_size']\n",
    "        hidden_size = args['hidden_size']\n",
    "        if epoch >= 2:\n",
    "            my_lr = my_lr/3\n",
    "        optimizer = torch.optim.SGD(net.parameters(), my_lr)\n",
    "        running_loss = 0\n",
    "        running_error = 0\n",
    "        num_batches = 0 \n",
    "        h = torch.zeros(1, bs, hidden_size)\n",
    "        c = torch.zeros(1, bs, hidden_size)\n",
    "        h = h.detach()\n",
    "        c = c.detach()\n",
    "#         # Send to gpu\n",
    "#         h = h.to(device)\n",
    "#         c = c.to(device)\n",
    "        shuffled_indices = torch.randperm(train_label.shape[0])\n",
    "        for count in range(0,train_label.shape[0],bs):\n",
    "            print('strat new batch')\n",
    "            # Create Random MiniBatch\n",
    "            indices = shuffled_indices[count:count+bs]\n",
    "            minibatch_data = train_dset[:,indices,:]\n",
    "            minibatch_label = train_label[indices]\n",
    "            # Send to gpu \n",
    "#             minibatch_data = minibatch_data.to(device)\n",
    "#             minibatch_label = minibatch_label.to(device)\n",
    "            # Normalized minibatch data\n",
    "            inputs = (minibatch_data - mean) /std\n",
    "            # Compute output \n",
    "            inputs.requires_grad_()\n",
    "            y = net(h, c, inputs)\n",
    "            # Compute Avg Loss\n",
    "            loss = criterion(y, minibatch_label.view(-1).long())\n",
    "            # backward \n",
    "            loss.backward()\n",
    "            # One step sgd\n",
    "            optimizer.step()\n",
    "            # Computing loss\n",
    "            running_loss += loss.detach().item()\n",
    "            # Computing error \n",
    "            error = get_error(y.detach(), minibatch_label)\n",
    "            running_error += error.item()\n",
    "\n",
    "            num_batches +=1\n",
    "        #Compute stats for the full training set\n",
    "        total_loss = running_loss/num_batches\n",
    "        total_error = running_error/num_batches\n",
    "        elapsed = (time.time()-start)/60\n",
    "    \n",
    "    \n",
    "        logger.write('epoch %d, time: %.2f' % (epoch, elapsed))\n",
    "        logger.write('\\t lr: %.3f' % (my_lr))\n",
    "        logger.write('\\t train loss: %.3f, train_error: %.3f' % (total_loss, total_error*100))\n",
    "        \n",
    "        net.train(False)\n",
    "        eval_error = eval_on_test_set(args, net, val_label, val_dset, device, mean, std)\n",
    "        net.train(True)\n",
    "        print('')\n",
    "        record = time.time()\n",
    "        if eval_error<best_error:\n",
    "            print('this epoch good, saved models')\n",
    "            model_pth = str(record)+'_'+name+'_EncDecmodel.pth'\n",
    "            torch.save(net,os.path.join(output,model_pth))\n",
    "            best_error = eval_error\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import errno\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "EPS = 1e-7\n",
    "\n",
    "\n",
    "def assert_eq(real, expected):\n",
    "    assert real == expected, '%s (true) vs %s (expected)' % (real, expected)\n",
    "\n",
    "\n",
    "def assert_array_eq(real, expected):\n",
    "    assert (np.abs(real-expected) < EPS).all(), \\\n",
    "        '%s (true) vs %s (expected)' % (real, expected)\n",
    "\n",
    "\n",
    "def load_folder(folder, suffix):\n",
    "    imgs = []\n",
    "    for f in sorted(os.listdir(folder)):\n",
    "        if f.endswith(suffix):\n",
    "            imgs.append(os.path.join(folder, f))\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def load_imageid(folder):\n",
    "    images = load_folder(folder, 'jpg')\n",
    "    img_ids = set()\n",
    "    for img in images:\n",
    "        img_id = int(img.split('/')[-1].split('.')[0].split('_')[-1])\n",
    "        img_ids.add(img_id)\n",
    "    return img_ids\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    \"\"\"custom weights initialization.\"\"\"\n",
    "    cname = m.__class__\n",
    "    if cname == nn.Linear or cname == nn.Conv2d or cname == nn.ConvTranspose2d:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif cname == nn.BatchNorm2d:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    else:\n",
    "        print('%s is not initialized.' % cname)\n",
    "\n",
    "\n",
    "def init_net(net, net_file):\n",
    "    if net_file:\n",
    "        net.load_state_dict(torch.load(net_file))\n",
    "    else:\n",
    "        net.apply(weights_init)\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError as exc:\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, output_name):\n",
    "        dirname = os.path.dirname(output_name)\n",
    "        if not os.path.exists(dirname):\n",
    "            os.mkdir(dirname)\n",
    "\n",
    "        self.log_file = open(output_name, 'w')\n",
    "        self.infos = {}\n",
    "\n",
    "    def append(self, key, val):\n",
    "        vals = self.infos.setdefault(key, [])\n",
    "        vals.append(val)\n",
    "\n",
    "    def log(self, extra_msg=''):\n",
    "        msgs = [extra_msg]\n",
    "        for key, vals in self.infos.iteritems():\n",
    "            msgs.append('%s %.6f' % (key, np.mean(vals)))\n",
    "        msg = '\\n'.join(msgs)\n",
    "        self.log_file.write(msg + '\\n')\n",
    "        self.log_file.flush()\n",
    "        self.infos = {}\n",
    "        return msg\n",
    "\n",
    "    def write(self, msg):\n",
    "        self.log_file.write(msg + '\\n')\n",
    "        self.log_file.flush()\n",
    "        print(msg)\n",
    "        \n",
    "def get_error( scores , labels ):\n",
    "\n",
    "    bs=scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels.view(-1) == labels.view(-1).long())\n",
    "    num_matches=indicator.sum()\n",
    "    \n",
    "    return 1-num_matches.float()/bs    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strat new batch\n",
      "tensor([[-0.2543, -0.1737, -0.1745,  ..., -0.1410, -0.1448, -0.0811],\n",
      "        [-0.2543, -0.1737, -0.1745,  ..., -0.1410, -0.1448, -0.0811],\n",
      "        [-0.2544, -0.1737, -0.1746,  ..., -0.1410, -0.1448, -0.0811],\n",
      "        ...,\n",
      "        [-0.2513, -0.1742, -0.1752,  ..., -0.1395, -0.1465, -0.0829],\n",
      "        [-0.2543, -0.1737, -0.1745,  ..., -0.1410, -0.1448, -0.0811],\n",
      "        [-0.2543, -0.1737, -0.1745,  ..., -0.1410, -0.1448, -0.0811]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0390,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1228],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1275,  0.1058,  0.0389,  0.1049, -0.1227],\n",
      "        [ 0.1278,  0.1061,  0.0398,  0.1057, -0.1235],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "tensor([[ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0390,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1228],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1275,  0.1058,  0.0389,  0.1049, -0.1227],\n",
      "        [ 0.1278,  0.1061,  0.0398,  0.1057, -0.1235],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227],\n",
      "        [ 0.1274,  0.1057,  0.0389,  0.1048, -0.1227]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "tensor([0, 3, 0, 0, 1, 1, 2, 0, 0, 0])\n",
      "1.552377700805664\n",
      "0.3999999761581421\n"
     ]
    }
   ],
   "source": [
    "# Build AN Function for Hyperparameter Tuning \n",
    "create_dir(output)\n",
    "best_error = 1000000\n",
    "bs = args['batch_size']\n",
    "hidden_size = args['hidden_size']\n",
    "optimizer = torch.optim.SGD(net.parameters(), my_lr)\n",
    "running_loss = 0\n",
    "running_error = 0\n",
    "num_batches = 0 \n",
    "h = torch.zeros(1, bs, hidden_size)\n",
    "c = torch.zeros(1, bs, hidden_size)\n",
    "h = h.detach()\n",
    "c = c.detach()\n",
    "#         # Send to gpu\n",
    "#         h = h.to(device)\n",
    "#         c = c.to(device)\n",
    "shuffled_indices = torch.randperm(train_label.shape[0])\n",
    "count = 0 \n",
    "print('strat new batch')\n",
    "# Create Random MiniBatch\n",
    "indices = shuffled_indices[count:count+bs]\n",
    "minibatch_data = train_dset[:,indices,:]\n",
    "minibatch_label = train_label[indices]\n",
    "# Send to gpu \n",
    "#             minibatch_data = minibatch_data.to(device)\n",
    "#             minibatch_label = minibatch_label.to(device)\n",
    "# Normalized minibatch data\n",
    "inputs = (minibatch_data - mean) /std\n",
    "# Compute output \n",
    "inputs.requires_grad_()\n",
    "y = net(h, c, inputs)\n",
    "# Compute Avg Loss\n",
    "loss = criterion(y, minibatch_label)\n",
    "print(y)\n",
    "print(minibatch_label)\n",
    "# backward \n",
    "loss.backward()\n",
    "# One step sgd\n",
    "optimizer.step()\n",
    "# Computing loss\n",
    "running_loss += loss.detach().item()\n",
    "print(running_loss)\n",
    "# Computing error \n",
    "error = get_error(y.detach(), minibatch_label)\n",
    "running_error += error.item()\n",
    "print(running_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = '/export/home/di0002ya/quickdraw/data/sy_data/model/'\n",
    "# train_enc_dec(args=args, net=net, my_lr=my_lr, train_label=train_label,train_dset=train_dset, \n",
    "#               device=device, mean=mean, std=std, output=output,name='simple', val_label=val_label, val_dset=val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "adv_mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
