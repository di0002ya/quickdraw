{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthors: Ding Shuya\\n\\nDescription: \\n\\nThis notebook will demonstrates CNN baseline models performance. \\n\\nDate: \\nWeek 8 \\n\\nHow to use?\\nChange dataset_path, output_path\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Authors: Ding Shuya\n",
    "\n",
    "Description: \n",
    "\n",
    "This notebook will demonstrate CNN baseline data preprocessing process.  \n",
    "\n",
    "Date: \n",
    "Week 8 \n",
    "\n",
    "How to use?\n",
    "Change dataset_path, output_path\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ndjson\n",
      "  Using cached https://files.pythonhosted.org/packages/39/ba/0628840da7b61fb63a6a0e030291a7a5e5d393a51cbcb27ded8b2a838aa9/ndjson-0.1.0-py2.py3-none-any.whl\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.15.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 1.10.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: ndjson\n",
      "Successfully installed ndjson-0.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "import os.path as path\n",
    "import glob\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(country_code,data):\n",
    "    splitted=[]\n",
    "    if isinstance(country_code,str):\n",
    "        country_code=country_code.split(' ')\n",
    "    for i in data:\n",
    "        if country_code!=-1 and i['countrycode']  not in country_code:\n",
    "            continue\n",
    "        # if i['recognized']==False:\n",
    "        #     continue\n",
    "        splitted.append((i['drawing'],i['word']))\n",
    "    return splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path='/export/home/di0002ya/quickdraw/data/sy_data/quick_draw/'\n",
    "class_name=['full_simplified_paintbrush'] #class_name==-1 means all class\n",
    "country_code=['JP'] #country_code==-1 means all countries\n",
    "output_path='/export/home/di0002ya/quickdraw/data/sy_data/quick_draw_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readding data from /export/home/di0002ya/quickdraw/data/sy_data/quick_draw/full_simplified_paintbrush.ndjson\n",
      "Now found 1379 avaliable data.\n"
     ]
    }
   ],
   "source": [
    "splitted=[]\n",
    "for file_path in glob.glob(path.join(dataset_path,'*.ndjson')):\n",
    "    label=file_path.split('/')[-1].split('.')[0]\n",
    "    if class_name!=-1 and label not in class_name:\n",
    "        continue\n",
    "    print('readding data from {}'.format(file_path))\n",
    "    with open(file_path) as f:\n",
    "        data = ndjson.load(f)\n",
    "    # for i in data[:4]:\n",
    "    #     print(i)\n",
    "    splitted+=split_data(country_code,data)\n",
    "    print('Now found {} avaliable data.'.format(len(splitted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that JP+PaintBrush data is insufficients. \n",
    "TODO LIST: \n",
    "1. We need to choose a large datasets (Visualization Requirements)\n",
    "2. We need to modify data generate scripts easy to import \n",
    "3. For multiclass classification, we need to select at least 10 classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(splitted)\n",
    "\n",
    "X=[i[0] for i in splitted]\n",
    "Y=[i[1] for i in splitted]\n",
    "with open(path.join(output_path,'data_X'),'wb') as f:\n",
    "    pickle.dump(X,f)\n",
    "\n",
    "with open(path.join(output_path,'data_Y'),'wb') as f:\n",
    "    pickle.dump(Y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading (Keisukeirie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scripts, I will use some codes from Keisukeirie. \n",
    "1. Class: CAT TIGER LION DOG \n",
    "2. Country: US\n",
    "3. Recognized: True \n",
    "4. Final Time: Less than 20000ms \n",
    "5. Strokes: 15 or less strokes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_json(class_list):\n",
    "    os.chdir('/export/home/di0002ya/quickdraw/data/sy_data/quick_draw/')\n",
    "    for cl in class_list:\n",
    "        os.system('wget https://storage.googleapis.com/quickdraw_dataset/full/raw/'+cl+'.ndjson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['cat', 'tiger', 'lion', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_json(class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing...We use lion as the examples CNN_feat_eng_pt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/export/home/di0002ya/quickdraw/data/sy_data/quick_draw/lion.ndjson', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature \"stroke_number\"\n",
    "df['stroke_number']=df['drawing'].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map \"recognized\"\n",
    "b_loon = {True: 1, False:0}\n",
    "df['recognized'] = df['recognized'].map(b_loon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/di0002ya/miniconda3/envs/ADV_MM/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# filter recoginized and stroke_number <15 and create_features final_time\n",
    "df_cf = df[(df['recognized']==1) & (df['stroke_number'] <= 15)]\n",
    "df_cf['final_time'] = [df_cf.loc[i,'drawing'][df_cf.stroke_number[i]-1][2][-1] for i in df_cf.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "Y = {}\n",
    "Ymax ={}\n",
    "time = {}\n",
    "ttnum_dp = {}\n",
    "sumtimeps = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wil do following operations for each samples \n",
    "1. X,Y,Time of each stroke in a temp list Xt,Yt,tt\n",
    "2. Calculate the difference between final and intial time of a stroke \n",
    "3. Normalize Xt and Yt\n",
    "4. Store them : get flatten X & Y for each samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0 \n",
    "num = df_cf.loc[i,'stroke_number']\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = [df_cf.loc[i,'drawing'][stroke][0] for stroke in range(num)]\n",
    "Yt = [df_cf.loc[i,'drawing'][stroke][1] for stroke in range(num)]\n",
    "tt = [df_cf.loc[i,'drawing'][stroke][2] for stroke in range(num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tdifftemp = [(df_cf.loc[i,'drawing'][stroke][2][-1] - df_cf.loc[i,'drawing'][stroke][2][0])\\\n",
    "             for stroke in range(num)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all X and all Y and all t \n",
    "Xtemp = [item for stroke in Xt for item in stroke]\n",
    "Ytemp = [item for stroke in Yt for item in stroke]\n",
    "time[i] = [item for stroke in tt for item in stroke]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _array_normalizer(array1,Xmin,Xmax,array_min):\n",
    "    '''\n",
    "    function:\n",
    "        - normalize X,Y array by range of X\n",
    "        - used in feature_eng_pt2\n",
    "    input:\n",
    "        array1 = array that you want to normalize (1D array or list)\n",
    "        Xmin = minimum value of your X array (int)\n",
    "        Xmax = maximum value of your X array (int)\n",
    "        array_min = minimum value of array1\n",
    "\n",
    "    output:\n",
    "        normalized array of array1\n",
    "    '''\n",
    "    return (np.array(array1)-np.array([array_min]*len(array1)))/float(Xmax-Xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xmintemp = np.min(Xtemp)-10\n",
    "Xmaxtemp = np.max(Xtemp)+10\n",
    "Ymintemp = np.min(Ytemp)-10\n",
    "Xnorm = _array_normalizer(Xtemp, Xmintemp,Xmaxtemp,Xmintemp)\n",
    "Ynorm = _array_normalizer(Ytemp, Xmintemp,Xmaxtemp,Ymintemp)\n",
    "Ymax[i] = np.max(Ynorm)\n",
    "X[i] = Xnorm\n",
    "Y[i] = Ynorm\n",
    "ttnum_dp[i] = len(Ynorm) #totoal number of data points \n",
    "sumtimeps[i] = sum(Tdifftemp)#totoal amount of time when user was drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttnum_dp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_cf.index:\n",
    "    num = df_cf.loc[i,'stroke_number']\n",
    "    #store X,Y,time of the stroke in a temp list\n",
    "    Xt = [df_cf.loc[i,'drawing'][stroke][0] for stroke in range(num)]\n",
    "    Yt = [df_cf.loc[i,'drawing'][stroke][1] for stroke in range(num)]\n",
    "    tt = [df_cf.loc[i,'drawing'][stroke][2] for stroke in range(num)]\n",
    "\n",
    "    # calculate the difference between final and initial time of a stroke\n",
    "    Tdifftemp = [(df_cf.loc[i,'drawing'][stroke][2][-1] - df_cf.loc[i,'drawing'][stroke][2][0])\\\n",
    "                 for stroke in range(num)]\n",
    "\n",
    "    # normalizing X and Y\n",
    "    Xtemp = [item for stroke in Xt for item in stroke]\n",
    "    Ytemp = [item for stroke in Yt for item in stroke]\n",
    "    time[i] = [item for stroke in tt for item in stroke]\n",
    "\n",
    "    #normalizing X and Y\n",
    "    Xmintemp = np.min(Xtemp)-10\n",
    "    Xmaxtemp = np.max(Xtemp)+10\n",
    "    Ymintemp = np.min(Ytemp)-10\n",
    "    Xnorm = _array_normalizer(Xtemp, Xmintemp,Xmaxtemp,Xmintemp)\n",
    "    Ynorm = _array_normalizer(Ytemp, Xmintemp,Xmaxtemp,Ymintemp)\n",
    "    Ymax[i] = np.max(Ynorm)\n",
    "    X[i] = Xnorm\n",
    "    Y[i] = Ynorm\n",
    "    ttnum_dp[i] = len(Ynorm)\n",
    "    sumtimeps[i] = sum(Tdifftemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new features and filter \n",
    "df_cf['total_number_of_datapoints'] = pd.Series(ttnum_dp)\n",
    "df_cf['Ymax'] = pd.Series(Ymax)\n",
    "df_cf['time'] = pd.Series(time)\n",
    "df_cf['total_time_drawing'] = pd.Series(sumtimeps)\n",
    "df_cf['X'] = pd.Series(X)\n",
    "df_cf['Y'] = pd.Series(Y)\n",
    "df_cf = df_cf[df_cf['Ymax']<=1.5]\n",
    "df_cf = df_cf[df_cf['final_time']<=20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['countrycode', 'drawing', 'key_id', 'recognized', 'timestamp', 'word',\n",
       "       'stroke_number', 'final_time', 'total_number_of_datapoints', 'Ymax',\n",
       "       'time', 'total_time_drawing', 'X', 'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cf.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96520, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cf[['Y']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing...\n",
    "\n",
    "1. We use lion as the examples CNN_feat_eng_pt2. \n",
    "2. Reformat input df to create CNN ready dataframe\n",
    "3. Generating a dataframe that will contains 1176 features per image 1176 = 42(Y axis) * 28 (X axis)\n",
    "4. It will also contain word and countrycode features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_index = df_cf.index\n",
    "df_cf.index = range(len(df_cf))\n",
    "image_pile = np.zeros((len(df_cf),1176))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216,)\n",
      "(216,)\n",
      "(216,)\n",
      "(216,)\n"
     ]
    }
   ],
   "source": [
    "ind = 0 \n",
    "print(df_cf.loc[ind,'X'].shape)\n",
    "print(np.array(df_cf.loc[ind,'X']).shape)\n",
    "print((np.array(df_cf.loc[ind,'X'])*28).shape)\n",
    "print(np.around(np.array(df_cf.loc[ind,'X'])*28).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now df_cf has 'X'and 'Y' columns which are arrays. \n",
    "After using np.around(np.array(df_cf.loc[ind,'X'])*28) still arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "xarray = np.around(np.array(df_cf.loc[ind,'X'])*28)\n",
    "yarray = np.around(np.array(df_cf.loc[ind,'Y'])*42/float(df_cf.loc[ind,'Ymax']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncating xarray and yarray to 27 and 41 if there valu is extremely large "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "xarray[xarray>=28.] = 27\n",
    "yarray[yarray>=42.] = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill image array by using time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((42,28))\n",
    "for item in range(len(xarray)):\n",
    "    image[int(np.around(yarray[item])),int(np.around(xarray[item]))] = df_cf.loc[ind,'time'][item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 28)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pile[0] = image.reshape(1,1176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_index = df_cf.index\n",
    "df_cf.index = range(len(df_cf))\n",
    "image_pile = np.zeros((len(df_cf),1176))\n",
    "for ind in df_cf.index:\n",
    "    image = np.zeros((42,28))\n",
    "    xarray = np.around(np.array(df_cf.loc[ind,'X'])*28)\n",
    "    yarray = np.around(np.array(df_cf.loc[ind,'Y'])*42/float(df_cf.loc[ind,'Ymax']))\n",
    "    xarray[xarray>=28.] = 27\n",
    "    yarray[yarray>=42.] = 41\n",
    "    for item in range(len(xarray)):\n",
    "        image[int(np.around(yarray[item])),int(np.around(xarray[item]))] = df_cf.loc[ind,'time'][item]\n",
    "    image_pile[ind] = image.reshape(1,1176)\n",
    "#return pd.DataFrame(image_pile, index = orig_index)\n",
    "df_final = pd.DataFrame(image_pile, index = orig_index)\n",
    "df_cf_country = df_cf['countrycode']\n",
    "df_cf_word = df_cf['word']\n",
    "df_cf_keyid = df_cf['key_id']\n",
    "df_cf_country.index = orig_index\n",
    "df_cf_word.index = orig_index\n",
    "df_cf_keyid.index = orig_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df_final,df_cf_country,df_cf_word,df_cf_keyid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            0,             1,             2,             3,\n",
       "                   4,             5,             6,             7,\n",
       "                   8,             9,\n",
       "       ...\n",
       "                1169,          1170,          1171,          1172,\n",
       "                1173,          1174,          1175, 'countrycode',\n",
       "              'word',      'key_id'],\n",
       "      dtype='object', length=1179)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.index = range(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 60000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ind = np.random.choice(list(df2.index), sample, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.loc[list(random_ind)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.index = df2['key_id']\n",
    "category = 'cat'\n",
    "df2.to_pickle(\"/export/home/di0002ya/quickdraw/data/sy_data/quick_draw_output/{}.pkl\".format(category))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "adv_mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
